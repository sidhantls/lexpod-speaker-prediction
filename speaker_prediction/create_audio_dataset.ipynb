{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8132940b",
   "metadata": {},
   "source": [
    "## Create Lex Speaker Dataset\n",
    "* Given all the podcasts and the labelled dataset of audioclips, write each of these audio clips. \n",
    "* These audio clips will be used for training the speaker prediction model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40d6b6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cuda available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import ffmpeg\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "print('is cuda available:', torch.cuda.is_available())\n",
    "\n",
    "# Add whisper repo to path to import\n",
    "repo_dir = Path(os.getcwd()).parents[0]/'whisper'\n",
    "sys.path.append(str(repo_dir))\n",
    "import whisper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f12b13c",
   "metadata": {},
   "source": [
    "### Labelled dataset\n",
    "\n",
    "* Contains start and end defining segment of the audio clip\n",
    "* audio_name is the name of the podcast. The podcasts audio files should be present in data/podcasts\n",
    "* `is_lex` is the label. 1 if speaker from start time to end time of the audio clip is lex. 0 if not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a164ce50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>fname</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>audio_idx</th>\n",
       "      <th>is_lex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02:49:11.280</td>\n",
       "      <td>02:49:15.120</td>\n",
       "      <td>And, you know, some people also ask, are you ...</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02:20:14.140</td>\n",
       "      <td>02:20:17.260</td>\n",
       "      <td>I still do that often.</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:19:15.360</td>\n",
       "      <td>00:19:17.320</td>\n",
       "      <td>things that you put into context of GPT.</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02:45:11.760</td>\n",
       "      <td>02:45:16.000</td>\n",
       "      <td>and that also gives, you know, huge perspecti...</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01:33:44.600</td>\n",
       "      <td>01:33:49.160</td>\n",
       "      <td>You, it's often the way how it works is you o...</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          start           end  \\\n",
       "0  02:49:11.280  02:49:15.120   \n",
       "1  02:20:14.140  02:20:17.260   \n",
       "2  00:19:15.360  00:19:17.320   \n",
       "3  02:45:11.760  02:45:16.000   \n",
       "4  01:33:44.600  01:33:49.160   \n",
       "\n",
       "                                                text        fname  \\\n",
       "0   And, you know, some people also ask, are you ...  episode_215   \n",
       "1                             I still do that often.  episode_215   \n",
       "2           things that you put into context of GPT.  episode_215   \n",
       "3   and that also gives, you know, huge perspecti...  episode_215   \n",
       "4   You, it's often the way how it works is you o...  episode_215   \n",
       "\n",
       "                                          audio_name  audio_idx  is_lex  \n",
       "0  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          0     0.0  \n",
       "1  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          1     1.0  \n",
       "2  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          2     0.0  \n",
       "3  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          3     0.0  \n",
       "4  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          4     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled_path = 'data/labelled_dataset.csv'\n",
    "df = pd.read_csv(labelled_path)\n",
    "\n",
    "assert df['audio_idx'].duplicated().sum() == 0\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37cc7f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num audio clips: 698\n",
      "Num unique podcasts: 68\n",
      "\n",
      "\n",
      "Postcasts containing the most tagged clips\n",
      "Elon Musk： Neuralink, AI, Autopilot, and the Pale Blue Dot ｜ Lex Fridman Podcast #49                   65\n",
      "Ray Dalio： Principles, the Economic Machine, AI & the Arc of Life ｜ Lex Fridman Podcast #54            21\n",
      "Judea Pearl： Causal Reasoning, Counterfactuals, and the Path to AGI ｜ Lex Fridman Podcast #56          21\n",
      "Dmitry Korkin： Computational Biology of Coronavirus ｜ Lex Fridman Podcast #90                          21\n",
      "Jeremy Howard： fast.ai Deep Learning Courses and Research ｜ Lex Fridman Podcast #35                    21\n",
      "Cumrun Vafa： String Theory ｜ Lex Fridman Podcast #204                                                  21\n",
      "Po-Shen Loh： Mathematics, Math Olympiad, Combinatorics & Contact Tracing ｜ Lex Fridman Podcast #183    20\n",
      "Jim Keller： Moore's Law, Microprocessors, and First Principles ｜ Lex Fridman Podcast #70               20\n",
      "Name: audio_name, dtype: int64\n",
      "\n",
      "\n",
      "Postcasts containing the least tagged clips\n",
      "Zach Bitter： Ultramarathon Running ｜ Lex Fridman Podcast #205                        1\n",
      "Whitney Cummings： Comedy, Robotics, Neurology, and Love ｜ Lex Fridman Podcast #55    1\n",
      "Name: audio_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "podcasts = list(df['audio_name'].unique())\n",
    "print('Num audio clips:', len(df))\n",
    "print(f'Num unique podcasts: {len(podcasts)}')\n",
    "\n",
    "print(f'\\n\\nPostcasts containing the most tagged clips\\n{df[\"audio_name\"].value_counts().head(8)}')\n",
    "print(f'\\n\\nPostcasts containing the least tagged clips\\n{df[\"audio_name\"].value_counts().tail(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588a59a2",
   "metadata": {},
   "source": [
    "### Create Audio Clips Dataset \n",
    "* Create individual audio segments based on the labelled data. So each audio clip will correspond to a label (is lex or not). \n",
    "* We'll be training our model to predict if the speaker in each audio clip is lex or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f144af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(in_file, out_file, start, end):\n",
    "    \"\"\"\n",
    "    Write a segment of the audio file. in_file is trimmed from start to end and written to out_file\n",
    "    \n",
    "    Inputs:\n",
    "        - in_file: path of the input audio pocast  \n",
    "        - out_file: path of the output audio clip \n",
    "        - start: start timestamp of the audio segment in in_file \n",
    "        - end: end timestap of audio segment in in_file. \n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if out_file.exists():\n",
    "        os.remove(out_file)\n",
    "\n",
    "    input_stream = ffmpeg.input(in_file)\n",
    "\n",
    "    pts = \"PTS-STARTPTS\"\n",
    "    audio = (input_stream\n",
    "             .filter_(\"atrim\", start=start, end=end)\n",
    "             .filter_(\"asetpts\", pts))\n",
    "    \n",
    "    output = ffmpeg.output(audio, str(out_file), format=\"mp3\")\n",
    "    output.run()\n",
    "\n",
    "    out_file_probe_result = ffmpeg.probe(out_file)\n",
    "    out_file_duration = out_file_probe_result.get(\n",
    "        \"format\", {}).get(\"duration\", None)\n",
    "\n",
    "def get_seconds(ts):\n",
    "    \"\"\"\n",
    "    Get seconds from timestamp\n",
    "    \n",
    "    \"\"\"\n",
    "    # convert to datetime instance\n",
    "    date_time = datetime.strptime(ts, '%H:%M:%S.%f')\n",
    "    time = date_time.hour * 3600 + date_time.minute * 60 + date_time.second + date_time.microsecond/10**6\n",
    "    \n",
    "    return time\n",
    "\n",
    "\n",
    "for write_dir in ['data', 'data/audio_dataset']:\n",
    "    write_dir = Path(write_dir)\n",
    "    \n",
    "    if not write_dir.exists():\n",
    "        write_dir.mkdir()\n",
    "\n",
    "# required podcasts expected to be present here\n",
    "clips_dir = Path(\"data/podcasts/\")\n",
    "if not clips_dir.exists():\n",
    "    raise ValueError('Expected lex podcasts audio files at', clips_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1a2969",
   "metadata": {},
   "source": [
    "### Write audio segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247a802",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████████████████████████████████████████████████████████                     | 515/698 [22:14<05:42,  1.87s/it]"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    audio_idx, audio_name = row.audio_idx, row.audio_name\n",
    "    start, end = row.start, row.end\n",
    "    \n",
    "    in_file = clips_dir/f\"{audio_name}.mp3\"\n",
    "    out_file = write_dir/f\"{audio_idx}.mp3\"\n",
    "    \n",
    "    assert in_file.exists()\n",
    "    trim(in_file, out_file, start, end)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebf0541",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "whisper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
