{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8132940b",
   "metadata": {},
   "source": [
    "## Speaker Identification using Whisper\n",
    "* Train a classification model to identify if the speaker in a audio segment is lex or not\n",
    "\n",
    "### Data:\n",
    "* Expecting training audio clips in data/audio_dataset. Download from [here](https://drive.google.com/drive/folders/1LkR8oskSMNFo-YV-YOGGPucr-J0nEk9W?usp=share_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "40d6b6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cuda available: True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "print('is cuda available:', torch.cuda.is_available())\n",
    "\n",
    "# Add whisper repo to path to import\n",
    "repo_dir = Path(os.getcwd()).parents[0]/'whisper'\n",
    "sys.path.append(str(repo_dir))\n",
    "import whisper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203a59d4",
   "metadata": {},
   "source": [
    "### Load Whisper model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22df1cea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = whisper.load_model(\"small.en\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ec877b",
   "metadata": {},
   "source": [
    "### Labelled dataset\n",
    "\n",
    "* Contains start and end defining segment of the audio clip\n",
    "* audio_name is the name of the podcast. The podcasts audio files should be present in data/lex_podcasts\n",
    "* `is_lex` is the label. 1 if speaker from start time to end time of the audio clip is lex. 0 if not\n",
    "\n",
    "#### Data augmentation:\n",
    "* All samples with audio_idx < 0 are auto generated based on keywords. Choose to use this however in training, since all audio clips will share a very similar spectral pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a164ce50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>fname</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>audio_idx</th>\n",
       "      <th>is_lex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02:49:11.280</td>\n",
       "      <td>02:49:15.120</td>\n",
       "      <td>And, you know, some people also ask, are you ...</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02:20:14.140</td>\n",
       "      <td>02:20:17.260</td>\n",
       "      <td>I still do that often.</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:19:15.360</td>\n",
       "      <td>00:19:17.320</td>\n",
       "      <td>things that you put into context of GPT.</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02:45:11.760</td>\n",
       "      <td>02:45:16.000</td>\n",
       "      <td>and that also gives, you know, huge perspecti...</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01:33:44.600</td>\n",
       "      <td>01:33:49.160</td>\n",
       "      <td>You, it's often the way how it works is you o...</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          start           end  \\\n",
       "0  02:49:11.280  02:49:15.120   \n",
       "1  02:20:14.140  02:20:17.260   \n",
       "2  00:19:15.360  00:19:17.320   \n",
       "3  02:45:11.760  02:45:16.000   \n",
       "4  01:33:44.600  01:33:49.160   \n",
       "\n",
       "                                                text        fname  \\\n",
       "0   And, you know, some people also ask, are you ...  episode_215   \n",
       "1                             I still do that often.  episode_215   \n",
       "2           things that you put into context of GPT.  episode_215   \n",
       "3   and that also gives, you know, huge perspecti...  episode_215   \n",
       "4   You, it's often the way how it works is you o...  episode_215   \n",
       "\n",
       "                                          audio_name  audio_idx  is_lex  \n",
       "0  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          0     0.0  \n",
       "1  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          1     1.0  \n",
       "2  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          2     0.0  \n",
       "3  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          3     0.0  \n",
       "4  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          4     0.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_dataset_dir = Path('data/audio_dataset')\n",
    "labelled_path = 'data/labelled_dataset.csv'\n",
    "df = pd.read_csv(labelled_path)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21ffec39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num audio clips: 698\n",
      "Num unique podcasts: 68\n",
      "\n",
      "\n",
      "Postcasts containing the most tagged clips\n",
      "Elon Musk： Neuralink, AI, Autopilot, and the Pale Blue Dot ｜ Lex Fridman Podcast #49                   65\n",
      "Ray Dalio： Principles, the Economic Machine, AI & the Arc of Life ｜ Lex Fridman Podcast #54            21\n",
      "Judea Pearl： Causal Reasoning, Counterfactuals, and the Path to AGI ｜ Lex Fridman Podcast #56          21\n",
      "Dmitry Korkin： Computational Biology of Coronavirus ｜ Lex Fridman Podcast #90                          21\n",
      "Jeremy Howard： fast.ai Deep Learning Courses and Research ｜ Lex Fridman Podcast #35                    21\n",
      "Cumrun Vafa： String Theory ｜ Lex Fridman Podcast #204                                                  21\n",
      "Po-Shen Loh： Mathematics, Math Olympiad, Combinatorics & Contact Tracing ｜ Lex Fridman Podcast #183    20\n",
      "Jim Keller： Moore's Law, Microprocessors, and First Principles ｜ Lex Fridman Podcast #70               20\n",
      "Name: audio_name, dtype: int64\n",
      "\n",
      "\n",
      "Postcasts containing the least tagged clips\n",
      "Zach Bitter： Ultramarathon Running ｜ Lex Fridman Podcast #205                        1\n",
      "Whitney Cummings： Comedy, Robotics, Neurology, and Love ｜ Lex Fridman Podcast #55    1\n",
      "Name: audio_name, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "podcasts = list(df['audio_name'].unique())\n",
    "print('Num audio clips:', len(df))\n",
    "print(f'Num unique podcasts: {len(podcasts)}')\n",
    "\n",
    "print(f'\\n\\nPostcasts containing the most tagged clips\\n{df[\"audio_name\"].value_counts().head(8)}')\n",
    "print(f'\\n\\nPostcasts containing the least tagged clips\\n{df[\"audio_name\"].value_counts().tail(2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbf9aa7",
   "metadata": {},
   "source": [
    "## Get Whisper Embeddings\n",
    "* Requires GPU to finish fast. If it takes too long on CPU, consider using a smaller Whisper model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e99f3dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 648/648 [01:43<00:00,  6.27it/s]\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    model = model.cuda()\n",
    "    \n",
    "if not os.path.exists(audio_dataset_dir):\n",
    "    if not audio_dataset_dir.exists():\n",
    "        raise ValueError('Expecting audio clips data in ', audio_dataset_dir)\n",
    "        \n",
    "filenames = df['audio_idx'].apply(lambda x: str(x) + '.mp3')\n",
    "audio_paths  = [audio_dataset_dir/filename for filename in filenames]\n",
    "\n",
    "idx_to_path = {idx: path for idx, path in enumerate(audio_paths)}\n",
    "\n",
    "hidden_l1 = []\n",
    "hidden_l2 = []\n",
    "hidden_last = []\n",
    "\n",
    "metadata_outputs = []\n",
    "for audio_path in tqdm(audio_paths, total=len(audio_paths), disable=False):\n",
    "    \n",
    "    assert os.path.exists(audio_path)\n",
    "\n",
    "    # load audio\n",
    "    audio = whisper.load_audio(str(audio_path))\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "    \n",
    "    # create mel spectogram input for whisper encoder\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "    mel = mel[None, :, :]\n",
    "    \n",
    "    # forward pass through encoder\n",
    "    with torch.no_grad():\n",
    "        _ = model.embed_audio(mel)\n",
    "    del _\n",
    "    \n",
    "    # get various hidden states of enocder\n",
    "    hidden_l1.append(model.encoder.encoder_out1.cpu())\n",
    "    hidden_l2.append(model.encoder.encoder_out2.cpu())\n",
    "    hidden_last.append(model.encoder.encoder_out_last.cpu())\n",
    "    \n",
    "    \n",
    "    metadata_outputs.append({\"metadata\": None, \"audio_path\": audio_path.name})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c964e628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>fname</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>audio_idx</th>\n",
       "      <th>is_lex</th>\n",
       "      <th>metadata</th>\n",
       "      <th>audio_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02:49:11.280</td>\n",
       "      <td>02:49:15.120</td>\n",
       "      <td>And, you know, some people also ask, are you ...</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02:20:14.140</td>\n",
       "      <td>02:20:17.260</td>\n",
       "      <td>I still do that often.</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>None</td>\n",
       "      <td>1.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00:19:15.360</td>\n",
       "      <td>00:19:17.320</td>\n",
       "      <td>things that you put into context of GPT.</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>2.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>02:45:11.760</td>\n",
       "      <td>02:45:16.000</td>\n",
       "      <td>and that also gives, you know, huge perspecti...</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>3.mp3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01:33:44.600</td>\n",
       "      <td>01:33:49.160</td>\n",
       "      <td>You, it's often the way how it works is you o...</td>\n",
       "      <td>episode_215</td>\n",
       "      <td>Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>None</td>\n",
       "      <td>4.mp3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          start           end  \\\n",
       "0  02:49:11.280  02:49:15.120   \n",
       "1  02:20:14.140  02:20:17.260   \n",
       "2  00:19:15.360  00:19:17.320   \n",
       "3  02:45:11.760  02:45:16.000   \n",
       "4  01:33:44.600  01:33:49.160   \n",
       "\n",
       "                                                text        fname  \\\n",
       "0   And, you know, some people also ask, are you ...  episode_215   \n",
       "1                             I still do that often.  episode_215   \n",
       "2           things that you put into context of GPT.  episode_215   \n",
       "3   and that also gives, you know, huge perspecti...  episode_215   \n",
       "4   You, it's often the way how it works is you o...  episode_215   \n",
       "\n",
       "                                          audio_name  audio_idx  is_lex  \\\n",
       "0  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          0     0.0   \n",
       "1  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          1     1.0   \n",
       "2  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          2     0.0   \n",
       "3  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          3     0.0   \n",
       "4  Wojciech Zaremba： OpenAI Codex, GPT-3, Robotic...          4     0.0   \n",
       "\n",
       "  metadata audio_path  \n",
       "0     None      0.mp3  \n",
       "1     None      1.mp3  \n",
       "2     None      2.mp3  \n",
       "3     None      3.mp3  \n",
       "4     None      4.mp3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.concat([df, pd.DataFrame(metadata_outputs)], axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4175f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# for checkpoint_dir in ['data', 'data/checkpoint']:\n",
    "#     checkpoint_dir = Path(checkpoint_dir)\n",
    "    \n",
    "#     if not checkpoint_dir.exists():\n",
    "#         checkpoint_dir.mkdir()\n",
    "        \n",
    "# df.to_csv(checkpoint_dir/'df_checkpoint.csv', index=False)\n",
    "\n",
    "# with open(checkpoint_dir/'vector_outputs2.pkl', 'wb') as f:\n",
    "#     pickle.dump(vector_outputs2, f)\n",
    "    \n",
    "# with open(checkpoint_dir/'vector_outputs.pkl', 'wb') as f:\n",
    "#     pickle.dump(vector_outputs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff336f",
   "metadata": {},
   "source": [
    "### Create Feature Vectors for Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "29237bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(vector_outputs):\n",
    "    \"\"\"\n",
    "    Get features to train classifier. \n",
    "    \n",
    "    Concatate mean features across 3 time windows \n",
    "    \n",
    "    \"\"\"\n",
    "    new_vectors = []\n",
    "    for row in vector_outputs:\n",
    "        out = [row[0, :500, :].mean(1).flatten(), row[0, 500:1000, :].mean(1).flatten(), row[0, 1000:, :].mean(1).flatten()]\n",
    "        new_vectors.append(torch.cat(out, -1)[None, :])\n",
    "        \n",
    "    new_vectors = torch.cat(new_vectors, 0)\n",
    "    return new_vectors\n",
    "\n",
    "def get_feature_vector2(vector_outputs):\n",
    "    \"\"\"\n",
    "    Get features to train classifier. \n",
    "    \n",
    "    Mean of features across entire timewindow of a clip\n",
    "    \n",
    "    \"\"\"\n",
    "    new_vectors = []\n",
    "    for row in vector_outputs:\n",
    "        out = row[0, :, :].mean(0)\n",
    "        new_vectors.append(out[None, :])\n",
    "        \n",
    "    new_vectors = torch.cat(new_vectors, 0)\n",
    "    return new_vectors\n",
    "\n",
    "def get_feature_vector3(vector_outputs):\n",
    "    \"\"\"\n",
    "    Get features to train classifier. \n",
    "    \n",
    "    Mean and std of features across entire timewindow of a clip\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    new_vectors = []\n",
    "    for row in vector_outputs:\n",
    "        out = row[0, :, :].mean(0)\n",
    "        out2 = row[0, :, :].std(0)\n",
    "        new_vectors.append(torch.cat([out[None, :], out2[None, :]], dim=1))\n",
    "        \n",
    "    new_vectors = torch.cat(new_vectors, 0)\n",
    "    return new_vectors\n",
    "\n",
    "\n",
    "new_vectors = get_feature_vector3(hidden_l1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2726af45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split found with ratio: {0.0: 0.5942028985507246, 1.0: 0.4057971014492754}: seed: 800\n",
      "Split found with ratio: {0.0: 0.5989010989010989, 1.0: 0.4010989010989011}: seed: 404\n",
      "Split found with ratio: {0.0: 0.5786516853932584, 1.0: 0.42134831460674155}: seed: 11\n",
      "Split found with ratio: {0.0: 0.5944444444444444, 1.0: 0.40555555555555556}: seed: 766\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np \n",
    "\n",
    "def cv_split(df, seed=42):\n",
    "    \"\"\"\n",
    "    Split on speaker\n",
    "    \"\"\"\n",
    "    \n",
    "    import random\n",
    "    \n",
    "    randgen = random.Random(seed)\n",
    "        \n",
    "    subdf = df[df['audio_idx'] >= 0]\n",
    "    \n",
    "    # negative audio_idx are not manually labelled, heuristically labelled. \n",
    "    # Near 100% are accurate, but speech pattern is same so only use few samples\n",
    "#     augmented_df = df[df['audio_idx'] < -1].sample(15)\n",
    "    augmented_df = pd.DataFrame()\n",
    "    \n",
    "    # split based on speakerid \n",
    "    sources = list(subdf['audio_name'].unique())\n",
    "    \n",
    "    test_split = randgen.sample(sources, len(sources) // 4)\n",
    "    train_split = list(set(sources).difference(test_split))\n",
    "\n",
    "    test_df = df[df['audio_name'].isin(test_split)]\n",
    "    train_df = df[df['audio_name'].isin(train_split)]\n",
    "    \n",
    "    # add heuristic data to labelled data\n",
    "    train_df = pd.concat([train_df, augmented_df], axis=0)\n",
    "                               \n",
    "    \n",
    "    return train_df, test_df\n",
    "    \n",
    "def generate_splits(df, num_splits=5):\n",
    "    \"\"\"\n",
    "    Splitting on speaker ID randomly leads to very high class imbalance in test set - in some podcasts lex tags are very few. \n",
    "    The strategy is to keep splitting on random seeds until a split of 40%-60% is reached\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    cvs = []\n",
    "    seen_seeds = set()\n",
    "    for split in range(num_splits):\n",
    "        seeds = np.random.randint(low=0, high=1000, size=(50,))\n",
    "        for seed in seeds: \n",
    "            # cant use same seed again \n",
    "            if seed in seen_seeds:\n",
    "                continue\n",
    "            train_df, test_df = cv_split(df, seed=seed)\n",
    "            counts = test_df['is_lex'].value_counts()\n",
    "            counts = counts/counts.sum()\n",
    "            if (counts.loc[1.0] >= 0.40) and (counts.loc[1.0] <= 0.60):\n",
    "                print(f'Split found with ratio: {counts.to_dict()}: seed: {seed}')\n",
    "                break \n",
    "                \n",
    "        cvs.append((train_df, test_df))\n",
    "        seen_seeds.add(seed)\n",
    "        \n",
    "    return cvs \n",
    "\n",
    "        \n",
    "splits = generate_splits(df, num_splits=5)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6fec6726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings \n",
    "from sklearn import preprocessing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn import svm\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "def get_metrics(true, pred):\n",
    "    f1, recall, precision, accuracy = f1_score(true, pred), recall_score(true, pred), precision_score(true, pred), accuracy_score(true, pred)\n",
    "    \n",
    "    return {'f1': f1, 'recall': recall, 'precision': precision, 'accuracy': accuracy}\n",
    "\n",
    "def train_eval(X, splits):\n",
    "    \"\"\"\n",
    "    Train model\n",
    "    \n",
    "    Inputs: \n",
    "        - X: All features X \n",
    "        - splits: List of tuples of (train_df, test_df)\n",
    "    \n",
    "    \"\"\"\n",
    "    test_metrics = []\n",
    "    train_metrics = []\n",
    "    fold_preds = []\n",
    "    for train_df, test_df in splits:\n",
    "        X_train, y_train = X[list(train_df.index), :], train_df['is_lex']\n",
    "        X_test, y_test = X[list(test_df.index), :], test_df['is_lex']\n",
    "\n",
    "        scalar = preprocessing.StandardScaler()\n",
    "        \n",
    "        # overfits fast with logistic regression\n",
    "#         clf = LogisticRegression(random_state=0, max_iter=15, C=.7)\n",
    "        clf = svm.SVC(kernel='rbf', C=.7)\n",
    "\n",
    "        pipeline = Pipeline([('transformer', scalar), ('estimator', clf)])\n",
    "\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        pred_train = pipeline.predict(X_train)\n",
    "        pred_test = pipeline.predict(X_test)\n",
    "\n",
    "\n",
    "        train_metrics.append(get_metrics(y_train, pred_train))\n",
    "        test_metrics.append(get_metrics(y_test, pred_test))\n",
    "        \n",
    "        fold_df = test_df.copy()\n",
    "        fold_df['preds'] = pred_test\n",
    "        \n",
    "        fold_preds.append(fold_df)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    train_metrics = pd.DataFrame(train_metrics)\n",
    "    test_metrics = pd.DataFrame(test_metrics)\n",
    "\n",
    "    display('Test stats ', test_metrics.describe().loc[[ 'mean','std']])\n",
    "    display('Train stats ', train_metrics.describe().loc[[ 'mean','std']])\n",
    "    \n",
    "    return train_metrics, test_metrics, fold_preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08481eef",
   "metadata": {},
   "source": [
    "## Featurize and train\n",
    "\n",
    "### Featurize:\n",
    "* Each hidden state is of shape (batch_size, 1500, hidden_size). The 1500 is the hidden state across 1500 time periods. We need to summarize features across the 3 time windows and create a feature vector of size (batch_size, hidden_size)\n",
    "* This what get_feature_vector functions do: \n",
    "    * `get_feature_vector3`: Performs the best. Creates mean and std features across time window. Concatenate mean and std across time. Creates feature of shape (batch_size, hidden_size + hidden_size).\n",
    "    * `get_feature_vector2`: Creates mean features across time windows. (batch_size, hidden_size)\n",
    "    * `get_feature_vector1`: Calculates mean features across 3 time windows of 1500 (1-500, 500-1000, 1000-1500). Creates feature shape of (batch_size, hidden_size * 3)\n",
    " \n",
    "### Train and Predict\n",
    "* Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40aeee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----Metrics of output of first_hidden encoder block output----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Test stats '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.705483</td>\n",
       "      <td>0.690793</td>\n",
       "      <td>0.736748</td>\n",
       "      <td>0.780618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.076161</td>\n",
       "      <td>0.127613</td>\n",
       "      <td>0.075481</td>\n",
       "      <td>0.052567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1    recall  precision  accuracy\n",
       "mean  0.705483  0.690793   0.736748  0.780618\n",
       "std   0.076161  0.127613   0.075481  0.052567"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Train stats '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.880556</td>\n",
       "      <td>0.813446</td>\n",
       "      <td>0.960803</td>\n",
       "      <td>0.936389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.036626</td>\n",
       "      <td>0.008286</td>\n",
       "      <td>0.006700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1    recall  precision  accuracy\n",
       "mean  0.880556  0.813446   0.960803  0.936389\n",
       "std   0.019417  0.036626   0.008286  0.006700"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----Metrics of output of second_hidden encoder block output----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Test stats '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.798997</td>\n",
       "      <td>0.812523</td>\n",
       "      <td>0.793472</td>\n",
       "      <td>0.843412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.039503</td>\n",
       "      <td>0.083739</td>\n",
       "      <td>0.063103</td>\n",
       "      <td>0.027118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1    recall  precision  accuracy\n",
       "mean  0.798997  0.812523   0.793472  0.843412\n",
       "std   0.039503  0.083739   0.063103  0.027118"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Train stats '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.933816</td>\n",
       "      <td>0.898089</td>\n",
       "      <td>0.972818</td>\n",
       "      <td>0.963249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009799</td>\n",
       "      <td>0.020933</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>0.003601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1    recall  precision  accuracy\n",
       "mean  0.933816  0.898089   0.972818  0.963249\n",
       "std   0.009799  0.020933   0.006511  0.003601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----Metrics of output of last_hidden encoder block output----\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Test stats '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.376044</td>\n",
       "      <td>0.251682</td>\n",
       "      <td>0.917949</td>\n",
       "      <td>0.693209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.146189</td>\n",
       "      <td>0.127624</td>\n",
       "      <td>0.092173</td>\n",
       "      <td>0.065150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1    recall  precision  accuracy\n",
       "mean  0.376044  0.251682   0.917949  0.693209\n",
       "std   0.146189  0.127624   0.092173  0.065150"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Train stats '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.740069</td>\n",
       "      <td>0.595155</td>\n",
       "      <td>0.994393</td>\n",
       "      <td>0.882272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.080055</td>\n",
       "      <td>0.105802</td>\n",
       "      <td>0.007821</td>\n",
       "      <td>0.025725</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1    recall  precision  accuracy\n",
       "mean  0.740069  0.595155   0.994393  0.882272\n",
       "std   0.080055  0.105802   0.007821  0.025725"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# utilize different hidden states for training and evaluate\n",
    "for X, hidden_name in zip([hidden_l1, hidden_l2, hidden_last], ['first_hidden', 'second_hidden', 'last_hidden']):\n",
    "          \n",
    "    # create features. \n",
    "    # X_use: (num_samples, 768 * 2)\n",
    "    X_use = get_feature_vector3(X)\n",
    "    \n",
    "    print(f'\\n----Metrics of output of {hidden_name} encoder block output----\\n')\n",
    "    train_metrics, test_metrics, pred_dfs = train_eval(X_use, splits)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af30245b",
   "metadata": {},
   "source": [
    "### Predict\n",
    "* Using hidden state at layer 2 performs the best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e88ac4b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Test stats '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.798997</td>\n",
       "      <td>0.812523</td>\n",
       "      <td>0.793472</td>\n",
       "      <td>0.843412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.039503</td>\n",
       "      <td>0.083739</td>\n",
       "      <td>0.063103</td>\n",
       "      <td>0.027118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1    recall  precision  accuracy\n",
       "mean  0.798997  0.812523   0.793472  0.843412\n",
       "std   0.039503  0.083739   0.063103  0.027118"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Train stats '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.933816</td>\n",
       "      <td>0.898089</td>\n",
       "      <td>0.972818</td>\n",
       "      <td>0.963249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.009799</td>\n",
       "      <td>0.020933</td>\n",
       "      <td>0.006511</td>\n",
       "      <td>0.003601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            f1    recall  precision  accuracy\n",
       "mean  0.933816  0.898089   0.972818  0.963249\n",
       "std   0.009799  0.020933   0.006511  0.003601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "X_use = get_feature_vector3(hidden_l2)\n",
    "train_metrics, test_metrics, pred_dfs = train_eval(X_use, splits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7d533233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Metrics '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "f1           0.785047\n",
       "recall       0.750000\n",
       "precision    0.823529\n",
       "accuracy     0.833333\n",
       "Name: 0, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Preds'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>fname</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>audio_idx</th>\n",
       "      <th>is_lex</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>02:04:05.240</td>\n",
       "      <td>02:04:10.240</td>\n",
       "      <td>Yes, he manipulated her as well, lied to her,...</td>\n",
       "      <td>episode_288</td>\n",
       "      <td>Sarma Melngailis： Bad Vegan, Fraud, Prison, an...</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>00:50:15.200</td>\n",
       "      <td>00:50:19.520</td>\n",
       "      <td>And in a sense, not really knowing what was g...</td>\n",
       "      <td>episode_288</td>\n",
       "      <td>Sarma Melngailis： Bad Vegan, Fraud, Prison, an...</td>\n",
       "      <td>21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>01:41:24.240</td>\n",
       "      <td>01:41:25.240</td>\n",
       "      <td>Thank you.</td>\n",
       "      <td>episode_288</td>\n",
       "      <td>Sarma Melngailis： Bad Vegan, Fraud, Prison, an...</td>\n",
       "      <td>22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>03:12:28.240</td>\n",
       "      <td>03:12:39.240</td>\n",
       "      <td>This sounds not to mock people, but this soun...</td>\n",
       "      <td>episode_288</td>\n",
       "      <td>Sarma Melngailis： Bad Vegan, Fraud, Prison, an...</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00:33:04.560</td>\n",
       "      <td>00:33:05.520</td>\n",
       "      <td>Alec Baldwin.</td>\n",
       "      <td>episode_288</td>\n",
       "      <td>Sarma Melngailis： Bad Vegan, Fraud, Prison, an...</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           start           end  \\\n",
       "19  02:04:05.240  02:04:10.240   \n",
       "20  00:50:15.200  00:50:19.520   \n",
       "21  01:41:24.240  01:41:25.240   \n",
       "22  03:12:28.240  03:12:39.240   \n",
       "23  00:33:04.560  00:33:05.520   \n",
       "\n",
       "                                                 text        fname  \\\n",
       "19   Yes, he manipulated her as well, lied to her,...  episode_288   \n",
       "20   And in a sense, not really knowing what was g...  episode_288   \n",
       "21                                         Thank you.  episode_288   \n",
       "22   This sounds not to mock people, but this soun...  episode_288   \n",
       "23                                      Alec Baldwin.  episode_288   \n",
       "\n",
       "                                           audio_name  audio_idx  is_lex  \\\n",
       "19  Sarma Melngailis： Bad Vegan, Fraud, Prison, an...         20     1.0   \n",
       "20  Sarma Melngailis： Bad Vegan, Fraud, Prison, an...         21     0.0   \n",
       "21  Sarma Melngailis： Bad Vegan, Fraud, Prison, an...         22     0.0   \n",
       "22  Sarma Melngailis： Bad Vegan, Fraud, Prison, an...         23     1.0   \n",
       "23  Sarma Melngailis： Bad Vegan, Fraud, Prison, an...         24     1.0   \n",
       "\n",
       "    preds  \n",
       "19    0.0  \n",
       "20    0.0  \n",
       "21    0.0  \n",
       "22    0.0  \n",
       "23    0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fold_idx = 0\n",
    "foldk_preds = pred_dfs[fold_idx]\n",
    "\n",
    "display('Metrics ', test_metrics.loc[fold_idx])\n",
    "\n",
    "display('Preds', foldk_preds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2a496e",
   "metadata": {},
   "source": [
    "#### List to audio_idx clip and explore the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "037b6b97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "      <th>fname</th>\n",
       "      <th>audio_name</th>\n",
       "      <th>audio_idx</th>\n",
       "      <th>is_lex</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>02:09:39.120</td>\n",
       "      <td>02:09:43.600</td>\n",
       "      <td>Long ago when you were baby Po or today</td>\n",
       "      <td>episode_183</td>\n",
       "      <td>Po-Shen Loh： Mathematics, Math Olympiad, Combi...</td>\n",
       "      <td>494</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>00:10:53.140</td>\n",
       "      <td>00:10:55.100</td>\n",
       "      <td>How do you think about language?</td>\n",
       "      <td>episode_120</td>\n",
       "      <td>François Chollet： Measures of Intelligence ｜ L...</td>\n",
       "      <td>431</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>00:33:04.560</td>\n",
       "      <td>00:33:05.520</td>\n",
       "      <td>Alec Baldwin.</td>\n",
       "      <td>episode_288</td>\n",
       "      <td>Sarma Melngailis： Bad Vegan, Fraud, Prison, an...</td>\n",
       "      <td>24</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>01:29:44.120</td>\n",
       "      <td>01:29:45.680</td>\n",
       "      <td>where you know what a fraction is</td>\n",
       "      <td>episode_183</td>\n",
       "      <td>Po-Shen Loh： Mathematics, Math Olympiad, Combi...</td>\n",
       "      <td>491</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>00:38:14.560</td>\n",
       "      <td>00:38:21.760</td>\n",
       "      <td>you know, if there are millions or billions o...</td>\n",
       "      <td>episode_154</td>\n",
       "      <td>Avi Loeb： Aliens, Black Holes, and the Mystery...</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>00:55:29.600</td>\n",
       "      <td>00:55:35.920</td>\n",
       "      <td>you'll be more tired in the afternoon. So if ...</td>\n",
       "      <td>episode_288</td>\n",
       "      <td>Sarma Melngailis： Bad Vegan, Fraud, Prison, an...</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>00:12:49.400</td>\n",
       "      <td>00:12:52.400</td>\n",
       "      <td>but the fact that a virus can just take over</td>\n",
       "      <td>episode_090</td>\n",
       "      <td>Dmitry Korkin： Computational Biology of Corona...</td>\n",
       "      <td>317</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>01:12:11.520</td>\n",
       "      <td>01:12:15.080</td>\n",
       "      <td>Something is still pushing things outward.</td>\n",
       "      <td>episode_232</td>\n",
       "      <td>Brian Greene： Quantum Gravity, The Big Bang, A...</td>\n",
       "      <td>594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>02:15:01.680</td>\n",
       "      <td>02:15:07.600</td>\n",
       "      <td>like proposing different kind of hypotheses o...</td>\n",
       "      <td>episode_154</td>\n",
       "      <td>Avi Loeb： Aliens, Black Holes, and the Mystery...</td>\n",
       "      <td>361</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>01:29:37.400</td>\n",
       "      <td>01:29:46.400</td>\n",
       "      <td>And then the third is, you know, things go mu...</td>\n",
       "      <td>episode_090</td>\n",
       "      <td>Dmitry Korkin： Computational Biology of Corona...</td>\n",
       "      <td>314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>02:13:13.240</td>\n",
       "      <td>02:13:27.240</td>\n",
       "      <td>Well, even before I knew there was ever going...</td>\n",
       "      <td>episode_288</td>\n",
       "      <td>Sarma Melngailis： Bad Vegan, Fraud, Prison, an...</td>\n",
       "      <td>26</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>01:58:38.320</td>\n",
       "      <td>01:58:43.040</td>\n",
       "      <td>black holes grow so fast? You know, less than...</td>\n",
       "      <td>episode_154</td>\n",
       "      <td>Avi Loeb： Aliens, Black Holes, and the Mystery...</td>\n",
       "      <td>375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>00:54:42.080</td>\n",
       "      <td>00:54:49.200</td>\n",
       "      <td>guy and irritated a lot of people, which is t...</td>\n",
       "      <td>episode_154</td>\n",
       "      <td>Avi Loeb： Aliens, Black Holes, and the Mystery...</td>\n",
       "      <td>374</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>00:58:07.800</td>\n",
       "      <td>00:58:10.600</td>\n",
       "      <td>in research mathematics or research other thi...</td>\n",
       "      <td>episode_183</td>\n",
       "      <td>Po-Shen Loh： Mathematics, Math Olympiad, Combi...</td>\n",
       "      <td>486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>01:13:28.480</td>\n",
       "      <td>01:13:35.680</td>\n",
       "      <td>because we're talking about this possibly ext...</td>\n",
       "      <td>episode_154</td>\n",
       "      <td>Avi Loeb： Aliens, Black Holes, and the Mystery...</td>\n",
       "      <td>360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            start           end  \\\n",
       "482  02:09:39.120  02:09:43.600   \n",
       "420  00:10:53.140  00:10:55.100   \n",
       "23   00:33:04.560  00:33:05.520   \n",
       "479  01:29:44.120  01:29:45.680   \n",
       "354  00:38:14.560  00:38:21.760   \n",
       "36   00:55:29.600  00:55:35.920   \n",
       "310  00:12:49.400  00:12:52.400   \n",
       "577  01:12:11.520  01:12:15.080   \n",
       "351  02:15:01.680  02:15:07.600   \n",
       "307  01:29:37.400  01:29:46.400   \n",
       "25   02:13:13.240  02:13:27.240   \n",
       "365  01:58:38.320  01:58:43.040   \n",
       "364  00:54:42.080  00:54:49.200   \n",
       "474  00:58:07.800  00:58:10.600   \n",
       "350  01:13:28.480  01:13:35.680   \n",
       "\n",
       "                                                  text        fname  \\\n",
       "482            Long ago when you were baby Po or today  episode_183   \n",
       "420                   How do you think about language?  episode_120   \n",
       "23                                       Alec Baldwin.  episode_288   \n",
       "479                  where you know what a fraction is  episode_183   \n",
       "354   you know, if there are millions or billions o...  episode_154   \n",
       "36    you'll be more tired in the afternoon. So if ...  episode_288   \n",
       "310       but the fact that a virus can just take over  episode_090   \n",
       "577         Something is still pushing things outward.  episode_232   \n",
       "351   like proposing different kind of hypotheses o...  episode_154   \n",
       "307   And then the third is, you know, things go mu...  episode_090   \n",
       "25    Well, even before I knew there was ever going...  episode_288   \n",
       "365   black holes grow so fast? You know, less than...  episode_154   \n",
       "364   guy and irritated a lot of people, which is t...  episode_154   \n",
       "474   in research mathematics or research other thi...  episode_183   \n",
       "350   because we're talking about this possibly ext...  episode_154   \n",
       "\n",
       "                                            audio_name  audio_idx  is_lex  \\\n",
       "482  Po-Shen Loh： Mathematics, Math Olympiad, Combi...        494     1.0   \n",
       "420  François Chollet： Measures of Intelligence ｜ L...        431     1.0   \n",
       "23   Sarma Melngailis： Bad Vegan, Fraud, Prison, an...         24     1.0   \n",
       "479  Po-Shen Loh： Mathematics, Math Olympiad, Combi...        491     0.0   \n",
       "354  Avi Loeb： Aliens, Black Holes, and the Mystery...        364     0.0   \n",
       "36   Sarma Melngailis： Bad Vegan, Fraud, Prison, an...         37     0.0   \n",
       "310  Dmitry Korkin： Computational Biology of Corona...        317     1.0   \n",
       "577  Brian Greene： Quantum Gravity, The Big Bang, A...        594     0.0   \n",
       "351  Avi Loeb： Aliens, Black Holes, and the Mystery...        361     1.0   \n",
       "307  Dmitry Korkin： Computational Biology of Corona...        314     1.0   \n",
       "25   Sarma Melngailis： Bad Vegan, Fraud, Prison, an...         26     1.0   \n",
       "365  Avi Loeb： Aliens, Black Holes, and the Mystery...        375     0.0   \n",
       "364  Avi Loeb： Aliens, Black Holes, and the Mystery...        374     0.0   \n",
       "474  Po-Shen Loh： Mathematics, Math Olympiad, Combi...        486     0.0   \n",
       "350  Avi Loeb： Aliens, Black Holes, and the Mystery...        360     1.0   \n",
       "\n",
       "     preds  \n",
       "482    1.0  \n",
       "420    1.0  \n",
       "23     0.0  \n",
       "479    0.0  \n",
       "354    0.0  \n",
       "36     0.0  \n",
       "310    1.0  \n",
       "577    0.0  \n",
       "351    1.0  \n",
       "307    1.0  \n",
       "25     0.0  \n",
       "365    0.0  \n",
       "364    0.0  \n",
       "474    0.0  \n",
       "350    1.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foldk_preds.sample(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab98a7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper",
   "language": "python",
   "name": "whisper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
